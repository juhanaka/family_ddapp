deepdive {

  # Regularization
  sampler.sampler_args: "-l 700 -s 1 -i 500 --alpha 0.1 --diminish 0.99 --reg_param 2"

  db.default {
    driver   : "org.postgresql.Driver"
    url      : "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user     : ${PGUSER}
    password : ${PGPASSWORD}
    dbname   : ${DBNAME}
    host     : ${PGHOST}
    port     : ${PGPORT}
  }


  pipeline.pipelines.preprocess_only: [
    "ext_clear_table_all", "ext_process_dependencies", "ext_people"
  ]

  #Choosing the pipeline to run
  #pipeline.run: "preprocess_only"

    # Put your variables here
  schema.variables {

  }

  # Put your extractors here
  extraction.extractors {
    # Clean output tables of all extractors
    ext_clear_table_all {
        style: "sql_extractor"
        sql: """
        DELETE FROM sentences_processed;
        DELETE FROM people_mentions;
        DELETE FROM has_spouse;
        DELETE FROM has_sibling;
        DELETE FROM has_parent;
        DELETE FROM has_spouse_features;
        DELETE FROM has_sibling_features;
        DELETE FROM has_parent_features;
        """
    }
    ext_process_dependencies {
        style: "json_extractor"
        input: """
        SELECT document_id,
                sentence,
                words,
                lemma,
                pos_tags,
                dependency_labels,
                dependency_parents,
                ner_tags,
                sentence_offset,
                sentence_id
        FROM sentences"""
        output_relation: "sentences_processed"
        udf: ${APP_HOME}"/udf/ext_dependencies.py"
        dependencies: ["ext_clear_table_all"]
    }
    # Extractor 2: extract people mentions:
    ext_people {
        # The style of the extractor
        style: "tsv_extractor"
        # An input to the extractor is a row (tuple) of the following query:
        input: """
        SELECT  sentence_id,
                array_to_string(words, '~^~'),
                array_to_string(ner_tags, '~^~')
            FROM  sentences"""
        # output of extractor will be written to this table:
        output_relation: "people_mentions"
        # This user-defined function will be performed on each row (tuple) of input query:
        udf: ${APP_HOME}"/udf/ext_people.py"
        dependencies: ["ext_process_dependencies"]
    }

    # Extractor 3: extract relationships:
    ext_has_spouse_candidates {
      # The style of the extractor
      style: tsv_extractor
      # Each input (p1, p2) is a pair of mentions
      input: """
        SELECT  sentences.sentence_id,
                p1.mention_id AS p1_mention_id,
                p1.text       AS p1_text,
                p2.mention_id AS p2_mention_id,
                p2.text       AS p2_text
         FROM   people_mentions p1,
                people_mentions p2,
                sentences
        WHERE   p1.sentence_id = p2.sentence_id
          AND   p1.sentence_id = sentences.sentence_id
          AND   p1.mention_id != p2.mention_id;
          """
      output_relation : "has_spouse"
      udf             : ${APP_HOME}"/udf/ext_has_spouse.py"

      # Run this extractor after "ext_people"
      dependencies    : ["ext_people"]
    }

    ext_has_sibling_candidates {
      # The style of the extractor
      style: tsv_extractor
      # Each input (p1, p2) is a pair of mentions
      input: """
        SELECT  sentences.sentence_id,
                p1.mention_id AS p1_mention_id,
                p1.text       AS p1_text,
                p2.mention_id AS p2_mention_id,
                p2.text       AS p2_text
         FROM   people_mentions p1,
                people_mentions p2,
                sentences
        WHERE   p1.sentence_id = p2.sentence_id
          AND   p1.sentence_id = sentences.sentence_id
          AND   p1.mention_id != p2.mention_id;
          """
      output_relation : "has_sibling"
      udf             : ${APP_HOME}"/udf/ext_has_sibling.py"

      # Run this extractor after "ext_people"
      dependencies    : ["ext_people"]
    }

    ext_has_parent_candidates {
      # The style of the extractor
      style: tsv_extractor
      # Each input (p1, p2) is a pair of mentions
      input: """
        SELECT  sentences.sentence_id,
                p1.mention_id AS p1_mention_id,
                p1.text       AS p1_text,
                p2.mention_id AS p2_mention_id,
                p2.text       AS p2_text
         FROM   people_mentions p1,
                people_mentions p2,
                sentences
        WHERE   p1.sentence_id = p2.sentence_id
          AND   p1.sentence_id = sentences.sentence_id
          AND   p1.mention_id != p2.mention_id;
          """
      output_relation : "has_parent"
      udf             : ${APP_HOME}"/udf/ext_has_parent.py"

      # Run this extractor after "ext_people"
      dependencies    : ["ext_people"]
    }
  }

  # Put your inference rules here
  inference.factors {
    }
  }
}
