deepdive {

  db.default {
    driver   : "org.postgresql.Driver"
    url      : "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user     : ${PGUSER}
    password : ${PGPASSWORD}
    dbname   : ${DBNAME}
    host     : ${PGHOST}
    port     : ${PGPORT}
  }

  # Put your variables here
  schema.variables {
  }
  pipeline.pipelines.preprocess_only: [
    "ext_clear_table_all", "ext_process_dependencies", "ext_people"
  ]

  pipeline.run: "preprocess_only"

  # Put your extractors here
  extraction.extractors {
    # Clean output tables of all extractors
    ext_clear_table_all {
        style: "sql_extractor"
        sql: """
        DELETE FROM sentences_processed;
        DELETE FROM people_mentions;
        """
    }
    ext_process_dependencies {
        style: "json_extractor"
        input: """
        SELECT document_id,
                sentence,
                words,
                lemma,
                pos_tags,
                dependency_labels,
                dependency_parents,
                ner_tags,
                sentence_offset,
                sentence_id
        FROM sentences"""
        output_relation: "sentences_processed"
        udf: ${APP_HOME}"/udf/ext_dependencies.py"
        dependencies: ["ext_clear_table_all"]
    }
    # Extractor 2: extract people mentions:
    ext_people {
        # The style of the extractor
        style: "tsv_extractor"
        # An input to the extractor is a row (tuple) of the following query:
        input: """
        SELECT  sentence_id,
                array_to_string(words, '~^~'),
                array_to_string(ner_tags, '~^~')
            FROM  sentences"""
        # output of extractor will be written to this table:
        output_relation: "people_mentions"
        # This user-defined function will be performed on each row (tuple) of input query:
        udf: ${APP_HOME}"/udf/ext_people.py"
        dependencies: ["ext_process_dependencies"]
    }
  }

  # Put your inference rules here
  inference.factors {
    }
  }
}
